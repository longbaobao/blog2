---
title: Python3入门机器学习 经典算法与应用
date: 2018-07-06 18:27:36
tags:
  - 算法与数据结构
  - Python3
  - 机器学习
  - 实战
  - 慕课网
categories:
  - 机器学习
keywords: Python3入门机器学习 经典算法与应用
---
第1章 欢迎来到 Python3 玩转机器学习
欢迎大家来到《Python3玩转机器学习》的课堂。在这个课程中，我们将从0开始，一点一点进入机器学习的世界。本门课程对机器学习领域的学习，绝不不仅仅只是对算法的学习，还包括诸如算法的评价，方法的选择，模型的优化，参数的调整，数据的整理，等等一系列工作。准备好了吗？现在开始我们的机器学习之旅！...

1-1 什么是机器学习
1-2 课程涵盖的内容和理念
1-3 课程所使用的主要技术栈
<!-- more -->
第2章 机器学习基础
机器学习到底是什么鬼？这一章将带领大家深入理解机器学习的世界，让大家去熟悉那些看似陌生的专业术语。监督学习，非监督学习，半监督学习，增强学习，批量学习，在线学习，参数学习，非参数学习。看完这一章，这些概念你就统统了解啦。不仅如此，本章还包含相当深刻地和机器学习相关的哲学探讨，让你深入思索有关机器学习...

2-1 机器学习世界的数据
2-2 机器学习的主要任务
2-3 监督学习，非监督学习，半监督学习和增强学习
2-4 批量学习，在线学习，参数学习和非参数学习
2-5 和机器学习相关的“哲学”思考
2-6 课程使用环境搭建
第3章 Jupyter Notebook, numpy和matplotlib
工欲善其事，必先利其器。在本章，我们将学习和机器学习相关的基础工具的使用：Jupyter Notebook, numpy和matplotlib。大多数教程在讲解机器学习的时候，大量使用这些工具，却不对这些工具进行系统讲解。我特意添加了这个章节，让同学们在后续编写机器学习算法的过程中，更加得心应手！...

3-1 Jupyter Notebook基础
3-2 Jupyter Notebook中的魔法命令
3-3 Numpy数据基础
3-4 创建Numpy数组(和矩阵)
3-5 Numpy数组(和矩阵)的基本操作
3-6 Numpy数组(和矩阵)的合并与分割
3-7 Numpy中的矩阵运算
3-8 Numpy中的聚合运算
3-9 Numpy中的arg运算
3-10 Numpy中的比较和Fancy Indexing
3-11 Matplotlib数据可视化基础
3-12 数据加载和简单的数据探索
第4章 最基础的分类算法-k近邻算法 kNN
k近邻算法本身是一个思想非常简单的算法，但是这个简单算法背后，也蕴含着丰富的内容。在这一章，我们将详细介绍k近邻算法的原理，进而对训练数据集，测试数据集，分类准确度，超参数，数据归一化，样本距离等基础概念进行详细的探讨。我们将详细了解scikit-learn框架中对算法的封装，并实现我们自己的算法框架。我们还将学...

4-1 k近邻算法基础
4-2 scikit-learn中的机器学习算法封装
4-3 训练数据集，测试数据集
4-4 分类准确度
4-5 超参数
4-6 网格搜索与k近邻算法中更多超参数
4-7 数据归一化
4-8 scikit-learn中的Scaler
4-9 更多有关k近邻算法的思考
第5章 线性回归法
线性回归法是机器学习领域的经典算法，很多更复杂的算法都是以线性回归为基础的。在这一章，我们将深入学习线性回归法背后的原理，同时仔细探讨如何评价回归算法。大家将对MSE,RMSE,MAE和R Squared等回归问题的评价指标有充分的理解。在实现层面上，我们还将学习机器学习领域的一个重要的实现技巧：向量化。...

5-1 简单线性回归
5-2 最小二乘法
5-3 简单线性回归的实现
5-4 向量化
5-5 衡量线性回归法的指标：MSE，RMSE和MAE
5-6 最好的衡量线性回归法的指标：R Squared
5-7 多元线性回归和正规方程解
5-8 实现多元线性回归
5-9 使用scikit-learn解决回归问题
5-10 线性回归的可解释性和更多思考
第6章 梯度下降法
梯度下降法是在机器学习领域的一个重要的搜索策略。在这一章，我们将详细讲解梯度下降法的基本原理，一步一步改进梯度下降算法，让大家理解梯度下降法中各种参数，尤其是学习率的意义。同时，我们还将引申出随机梯度下降法和小批量梯度下降法两个方法，让大家对梯度下降法家族有一个全方位的认识。...

6-1 什么是梯度下降法
6-2 模拟实现梯度下降法
6-3 线性回归中的梯度下降法
6-4 实现线性回归中的梯度下降法
6-5 梯度下降法的向量化和数据标准化
6-6 随机梯度下降法
6-7 scikit-learn中的随机梯度下降法
6-8 如何确定梯度计算的准确性？调试梯度下降法
6-9 有关梯度下降法的更多深入讨论
第7章 PCA与梯度上升法
通常教材会使用非常多的数学概念来讲解PCA，在这个课程中，我们将另辟蹊径，绕开繁重的数学概念，使用梯度下降法的姊妹方法：梯度上升法来求解PCA问题，进而深刻理解PCA的基本原理，如何使用PCA进行数据的降维。我们还将给出多个PCA的应用场景，不仅让大家亲手实践出PCA降维的巨大威力，也让大家看到PCA在降噪，人脸识别等...

7-1 什么是PCA
7-2 使用梯度上升法求解PCA问题
7-3 求数据的主成分PCA
7-4 求数据的前n个主成分
7-5 高维数据映射为低维数据
7-6 scikit-learn中的PCA
7-7 试手MNIST数据集
7-8 使用PCA对数据进行降噪
7-9 人脸识别与特征脸
第8章 多项式回归与模型泛化
在这一章，我们将接触非线性问题。我们将学习多项式回归的思想，使用线性回归的思路来解决非线性问题。进一步，我们将引申出或许是机器学习领域最重要的一个问题：模型泛化问题。我们将深入探讨什么是欠拟合，什么是过拟合，怎样检测欠拟合和过拟合。什么是交叉验证，什么是模型正则化。听起来拗口的Ridge和Lasso都是什么鬼...

8-1 什么是多项式回归
8-2 scikit-learn中的多项式回归与Pipeline
8-3 过拟合与欠拟合
8-4 为什么要有训练数据集与测试数据集
8-5 学习曲线
8-6 验证数据集与交叉验证
8-7 偏差方差平衡
8-8 模型泛化与岭回归
8-9 LASSO
8-10 L1, L2和弹性网络
第9章 逻辑回归
据统计，逻辑回归是机器学习领域最常用的分类算法，没有之一！在这一章，我们将逐渐揭开逻辑回归的神秘面纱，了解如何应用线性回归的思路，来解决分类问题。我们将综合之前所学习的很多内容，一点一点来完善我们的逻辑回归模型。我们还将继续深入分类问题，学习对分类结果概率的估计，以及决策边界等重要概念。 ...

9-1 什么是逻辑回归
9-2 逻辑回归的损失函数
9-3 逻辑回归损失函数的梯度
9-4 实现逻辑回归算法
9-5 决策边界
9-6 在逻辑回归中使用多项式特征
9-7 scikit-learn中的逻辑回归
9-8 OvR与OvO
第10章 评价分类结果
对机器学习分类算法结果的评估，是一个公认的复杂问题。在这一章，我们将来阐述这个问题为什么复杂。我们如何更好地看待我们的机器学习算法给出的结果。学习诸如混淆矩阵，准确率，精确率，召回率，F1，以及ROC等诸多评价分类结果的指标。通过这一章的学习，大家将更好地理解自己的机器学习算法给出的结果，从而在实际应用...

10-1 准确度的陷阱和混淆矩阵
10-2 精准率和召回率
10-3 实现混淆矩阵，精准率和召回率
10-4 F1 Score
10-5 精准率和召回率的平衡
10-6 精准率-召回率曲线
10-7 ROC曲线
10-8 多分类问题中的混淆矩阵
第11章 支撑向量机 SVM
在这一章，我们将深入学习大名鼎鼎的支撑向量机SVM。我们将从线性SVM开始，理解SVM的思路，进而深入理解SVM解决非线性问题的方式——核函数。我们将重点学习两个最重要的核函数：多项式核和径向基函数核。我们更会使用真实的数据集实验，看到SVM的优缺点。最后，我们还将探讨使用SVM解决回归问题的思路。 ...

11-1 什么是SVM
11-2 SVM背后的最优化问题
11-3 Soft Margin SVM
11-4 scikit-learn中的SVM
11-5 SVM中使用多项式特征和核函数
11-6 到底什么是核函数
11-7 RBF核函数
11-8 RBF核函数中的gamma
11-9 SVM思想解决回归问题
第12章 决策树
在这一章，我们将学习另外一个大名鼎鼎的机器学习算法：决策树。决策树本身非常简单，背后并没有复杂的数学模型，但使用好决策树也有很多技巧。我们将深入了解什么是熵模型，什么是基尼系数，怎样使用决策树解决分类问题，怎样获得分类的概率，怎样用决策树解决回归问题，以及使用决策树的注意事项。 ...

12-1 什么是决策树
12-2 信息熵
12-3 使用信息熵寻找最优划分
12-4 基尼系数
12-5 CART与决策树中的超参数
12-6 决策树解决回归问题
12-7 决策树的局限性
第13章 集成学习和随机森林
集成学习的思想是机器学习领域解决问题的一种重要思想。我们将从集成之前已经学习过的算法出发，进而引入集成学习的经典算法：随机森林。我们将看到集成学习的威力。在这一章，我们还会对其他集成学习的思想，如AdaBoost, Gradient Boosting, Stacking等算法进行介绍。 ...

13-1 什么是集成学习
13-2 Soft Voting Classifier
13-3 Bagging 和 Pasting
13-4 oob (Out-of-Bag) 和关于Bagging的更多讨论
13-5 随机森林和 Extra-Trees
13-6 Ada Boosting 和 Gradient Boosting
13-7 Stacking
第14章 更多机器学习算法
相信通过这个课程的学习。同学们学到的不仅仅是一个一个零散的机器学习算法，更对机器学领域解决问题的方式有了一个系统性的认识。学会了这种思维方法，相信大家都可以更好地继续深入学习机器学习。在最后，我将给大家介绍scikit-learn的文档，希望大家能够借助scikit-learn这个强大的机器学习库，继续探索机器学习这个当下...

14-1 学习scikit-learn文档, 大家加油！
14-2 学习完这个课程以后怎样继续深入机器学习的学习？
本课程已完结

<div id="jspay" sid="E5fPEvB2818" style="display:none">E5fPEvB2818</div>
<script type="text/javascript" src="https://www.fageka.com/j.js"></script>
<script type="text/javascript" src="https://www.fageka.com/f.js" charset="utf-8"></script>
